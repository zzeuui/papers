## Deformable DETR: Deformable transformers for end-to-end object detection(2021)
ICLR 2021 Oral  
[[paper](https://arxiv.org/pdf/2010.04159v4.pdf)]
[[code](https://github.com/fundamentalvision/Deformable-DETR)]

### ğŸ’¡Problem & Motivation  
DETRì€ ë‘ê°€ì§€ ë¬¸ì œë¥¼ ê°€ì§„ë‹¤:
1. ê¸°ì¡´ Object detectorë³´ë‹¤ ìˆ˜ë ´í•˜ëŠ”ë° í›¨ì”¬ ê¸´ í•™ìŠµ ì‹œê°„ì´ í•„ìš”í•¨
2.  feature spatial resolutionì´ ì œí•œë˜ì–´ ì‘ì€ ë¬¼ì²´ë¥¼ íƒì§€í•˜ëŠ”ë° ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ì„±ëŠ¥ì„ ê°€ì§

DETRì´ ê°€ì§„ TransformerëŠ” ê°€ëŠ¥í•œ ëª¨ë“  ê³µê°„ì˜ ìœ„ì¹˜ë¥¼ ì¡°ì‚¬í•˜ë ¤ê³  í•´ ì˜¤ëœ í•™ìŠµ ì‹œê°„ì´ í•„ìš”í•¨.  
$\Rightarrow$ ì´ë¯¸ì§€ ì˜ì—­ì—ì„œ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•œ deformable convolutionê³¼ transformerì˜ ë³µì¡ì„±ì„ í•´ê²°í•˜ê¸° ìœ„í•œ
data-dependent sparse attentionì—ì„œ ì˜ê°ì„ ì–»ì–´, reference points ì£¼ë³€ì—ì„œ ìƒ˜í”Œë§í•œ pointsë¡œ êµ¬ì„±ëœ ì‘ì€ ì§‘í•©ìœ¼ë¡œ attentionì„ ìˆ˜í–‰í•˜ëŠ” Deformable DETRì„ ì œì•ˆ.

### ğŸ’¡Method
- **Deformable attention module**: feature mapì˜ ê³µê°„ì  í¬ê¸°ì™€ ìƒê´€ì—†ì´ reference point ì£¼ë³€ì—ì„œ ìƒ˜í”Œë§ëœ ì£¼ìš” pointsì˜ ì§‘í•©ì— ëŒ€í•´ attentioní•œë‹¤. (<=> feature ì „ì²´ì— ëŒ€í•´ì„œ attentioní•˜ì§€ ì•ŠìŒ)
- **Multi-scale deformable attention module**: backbone ë„¤íŠ¸ì›Œí¬ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ì‚¬ì´ì¦ˆë¥¼ ê°€ì§€ëŠ” ì—¬ëŸ¬ stageì˜ feature mapsì„ ì‚¬ìš©í•œë‹¤.

<img src="https://github.com/zzeuui/papers/assets/38878047/9ba9db0e-e42d-454e-bb67-6cb39a4976fa" width=90%>

- **Deformable transformer encoder**: ë‹¤ì–‘í•œ í¬ê¸°ì˜ featureì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ 1*1 convolutionìœ¼ë¡œ í¬ê¸°ë¥¼ ë§ì¶°ì¤€ë‹¤.
- **Deformable transformer decoder**: self-attetionì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , cross-attentionë¶€ë¶„ì„ Multi-scale deformable attention moduleë¡œ ëŒ€ì²´í•œë‹¤.

### ğŸ’¡Experiment
- Deformable DETRì€ 10ë°° ì ì€ í•™ìŠµ ì‹œê°„ìœ¼ë¡œ DETRë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•œë‹¤.
